{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySpark.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNgppUhhjXq3rEyMgwF2nQR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spyrgalaz/Deep_Neural_Networks/blob/main/PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dvHWXnUt7pF"
      },
      "source": [
        "# Running Pyspark in Colab\n",
        "To run spark in Colab, we need to first install all the dependencies in Colab environment i.e. Apache Spark 2.3.2 with hadoop 2.7, Java 8 and Findspark to locate the spark in the system. The tools installation can be carried out inside the Jupyter Notebook of the Colab. One important note is that if you are new in Spark, it is better to avoid Spark 2.4.0 version since some people have already complained about its compatibility issue with python. Follow the steps to install the dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s19OA9dlMZGz"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBi-TjshMend",
        "outputId": "52b928c2-dec4-4346-f4e5-024c5d431e2b"
      },
      "source": [
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz\r\n",
        "!pip install -q findspark\r\n",
        "!pip install pyspark"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzoRyFBUxq8X"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2nReGJYxx8e"
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "import pyspark\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be2GpwK5TCUm"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbhLFRXruLDs"
      },
      "source": [
        "# Linear Regression Model\n",
        "Linear Regression model is one the oldest and widely used machine learning approach which assumes a relationship between dependent and independent variables. For example, a modeler might want to predict the forecast of the rain based on the humidity ratio. Linear Regression consists of the best fitting line through the scattered points on the graph and the best fitting line is known as the regression line.\n",
        "\n",
        "The goal of this exercise to predict the housing prices by the given features. Let's predict the prices of the Boston Housing dataset by considering MEDV as the output variable and all the other variables as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeUA8MFRrWwd"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "\n",
        "flights = spark.read.csv('/content/flights-larger.csv',inferSchema=True, header =True,nullValue='NA')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRfAv9C6lTXo",
        "outputId": "bad0e7bf-0ae6-4c77-d206-3c20255af741"
      },
      "source": [
        "flights.show(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
            "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
            "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
            "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
            "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
            "+---+---+---+-------+------+---+----+------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTENtVNsfCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53817711-b1ec-4f1d-cd72-8ba207ee1c25"
      },
      "source": [
        "flights.printSchema()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- mon: integer (nullable = true)\n",
            " |-- dom: integer (nullable = true)\n",
            " |-- dow: integer (nullable = true)\n",
            " |-- carrier: string (nullable = true)\n",
            " |-- flight: integer (nullable = true)\n",
            " |-- org: string (nullable = true)\n",
            " |-- mile: integer (nullable = true)\n",
            " |-- depart: double (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- delay: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oARo_xLum1NG",
        "outputId": "ad5efe9f-679b-49d8-eba9-63eaf832d7a9"
      },
      "source": [
        "print(flights.dtypes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQCnTA5OxHPF",
        "outputId": "5f280102-7c4c-4476-c7a8-0323222f5db1"
      },
      "source": [
        "print(\"The data contain %d records.\" % flights.count())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The data contain 29418 records.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9R548AsxZVV",
        "outputId": "8641a127-e76e-4d48-b4ee-de667f1efdae"
      },
      "source": [
        "# Remove the 'flight' column\r\n",
        "flights_drop_column = flights.drop('flight')\r\n",
        "print(flights_drop_column.show(5))\r\n",
        "# Number of records with missing 'delay' values\r\n",
        "flights_drop_column.filter('delay IS NULL').count()\r\n",
        "print(flights_drop_column.show(5))\r\n",
        "# Remove records with missing 'delay' values\r\n",
        "flights_valid_delay = flights_drop_column.filter('delay IS NOT NULL')\r\n",
        "print(flights_valid_delay.show(5))\r\n",
        "# Remove records with missing values in any column and get the number of remaining rows\r\n",
        "flights_none_missing = flights_valid_delay.dropna()\r\n",
        "print(flights_none_missing.count())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "|mon|dom|dow|carrier|org|mile|depart|duration|delay|\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "| 10| 10|  1|     OO|ORD| 157|  8.18|      51|   27|\n",
            "|  1|  4|  1|     OO|ORD| 466|  15.5|     102| null|\n",
            "| 11| 22|  1|     OO|ORD| 738|  7.17|     127|  -19|\n",
            "|  2| 14|  5|     B6|JFK|2248| 21.17|     365|   60|\n",
            "|  5| 25|  3|     WN|SJC| 386| 12.92|      85|   22|\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "|mon|dom|dow|carrier|org|mile|depart|duration|delay|\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "| 10| 10|  1|     OO|ORD| 157|  8.18|      51|   27|\n",
            "|  1|  4|  1|     OO|ORD| 466|  15.5|     102| null|\n",
            "| 11| 22|  1|     OO|ORD| 738|  7.17|     127|  -19|\n",
            "|  2| 14|  5|     B6|JFK|2248| 21.17|     365|   60|\n",
            "|  5| 25|  3|     WN|SJC| 386| 12.92|      85|   22|\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "|mon|dom|dow|carrier|org|mile|depart|duration|delay|\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "| 10| 10|  1|     OO|ORD| 157|  8.18|      51|   27|\n",
            "| 11| 22|  1|     OO|ORD| 738|  7.17|     127|  -19|\n",
            "|  2| 14|  5|     B6|JFK|2248| 21.17|     365|   60|\n",
            "|  5| 25|  3|     WN|SJC| 386| 12.92|      85|   22|\n",
            "|  3| 28|  1|     B6|LGA|1076| 13.33|     182|   70|\n",
            "+---+---+---+-------+---+----+------+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n",
            "None\n",
            "27594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shspn1JZnN3W"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsVfBM2KUjmB"
      },
      "source": [
        "\r\n",
        "flights=flights_none_missing"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuATeVNDzBnw",
        "outputId": "473b5f74-9ab5-4eeb-8d6b-ca07bc02a2f3"
      },
      "source": [
        "# Import the required function\r\n",
        "from pyspark.sql.functions import round\r\n",
        "\r\n",
        "# Convert 'mile' to 'km' and drop 'mile' column\r\n",
        "flights_km = flights.withColumn('km', round(flights.mile * 1.60934, 0)) \\\r\n",
        "                    .drop('mile')\r\n",
        "\r\n",
        "# Create 'label' column indicating whether flight delayed (1) or not (0)\r\n",
        "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\r\n",
        "\r\n",
        "# Check first five records\r\n",
        "flights_km.show(5)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|\n",
            "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|\n",
            "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|\n",
            "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|\n",
            "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tdV_ySv4UOW"
      },
      "source": [
        "flights=flights_km"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-gSowDuzap7"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\r\n",
        "\r\n",
        "# Create an indexer\r\n",
        "indexer = StringIndexer(inputCol='carrier', outputCol='carrier_idx')\r\n",
        "\r\n",
        "# Indexer identifies categories in the data\r\n",
        "indexer_model = indexer.fit(flights)\r\n",
        "\r\n",
        "# Indexer creates a new column with numeric index values\r\n",
        "flights_indexed = indexer_model.transform(flights)\r\n",
        "\r\n",
        "# Repeat the process for the other categorical feature\r\n",
        "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJdDSivu08f_",
        "outputId": "ad2c5717-bd85-4fcb-e4cd-6a4db2a5a7f1"
      },
      "source": [
        "flights_indexed.show(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
            "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
            "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|\n",
            "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|\n",
            "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|\n",
            "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|\n",
            "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skxpq-Ne1fl3"
      },
      "source": [
        "flights=flights_indexed"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx-CoFIxzvUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d727a21-ab78-487e-9188-b1c3d3bcffd2"
      },
      "source": [
        "# Import the necessary class\r\n",
        "from pyspark.ml.feature import VectorAssembler\r\n",
        "\r\n",
        "# Create an assembler object\r\n",
        "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow', 'carrier_idx', 'org_idx', 'km', 'depart', 'duration'],outputCol='features')\r\n",
        "\r\n",
        "# Consolidate predictor columns\r\n",
        "flights_assembled = assembler.transform(flights)\r\n",
        "\r\n",
        "# Check the resulting column\r\n",
        "flights_assembled.select('features', 'delay').show(5, truncate=False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------------+-----+\n",
            "|features                                 |delay|\n",
            "+-----------------------------------------+-----+\n",
            "|[10.0,10.0,1.0,2.0,0.0,253.0,8.18,51.0]  |27   |\n",
            "|[11.0,22.0,1.0,2.0,0.0,1188.0,7.17,127.0]|-19  |\n",
            "|[2.0,14.0,5.0,4.0,2.0,3618.0,21.17,365.0]|60   |\n",
            "|[5.0,25.0,3.0,3.0,5.0,621.0,12.92,85.0]  |22   |\n",
            "|[3.0,28.0,1.0,4.0,3.0,1732.0,13.33,182.0]|70   |\n",
            "+-----------------------------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttitrSoTxZal"
      },
      "source": [
        "ONE HOT ENCODER   DON'T USE IT FOR FLIGHT-LARGER SET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckPAlkKcsyel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af741a5-0328-4365-94b8-a52539bc03d6"
      },
      "source": [
        "# Import the one hot encoder class\n",
        "from pyspark.ml.feature import OneHotEncoderEstimator\n",
        "\n",
        "# Create an instance of the one hot encoder\n",
        "onehot = OneHotEncoderEstimator(inputCols=['org_idx'], outputCols=['org_dummy'])\n",
        "\n",
        "# Apply the one hot encoder to the flights data\n",
        "onehot = onehot.fit(flights)\n",
        "flights_onehot = onehot.transform(flights)\n",
        "\n",
        "# Check the results\n",
        "flights_onehot.select('org', 'org_idx', 'org_dummy').distinct().sort('org_idx').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------+-------------+\n",
            "|org|org_idx|    org_dummy|\n",
            "+---+-------+-------------+\n",
            "|ORD|    0.0|(7,[0],[1.0])|\n",
            "|SFO|    1.0|(7,[1],[1.0])|\n",
            "|JFK|    2.0|(7,[2],[1.0])|\n",
            "|LGA|    3.0|(7,[3],[1.0])|\n",
            "|SMF|    4.0|(7,[4],[1.0])|\n",
            "|SJC|    5.0|(7,[5],[1.0])|\n",
            "|TUS|    6.0|(7,[6],[1.0])|\n",
            "|OGG|    7.0|    (7,[],[])|\n",
            "+---+-------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZCe7jdPkiyp"
      },
      "source": [
        "flights=flights_assembled"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjBnqyUatTxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbd0f435-48a4-4ba5-dbab-78905d835765"
      },
      "source": [
        "# Split into training and testing sets in a 80:20 ratio\n",
        "flights_train, flights_test = flights.randomSplit([0.8, 0.2], seed=17)\n",
        "\n",
        "# Check that training set has around 80% of records\n",
        "training_ratio = flights_train.count() / flights.count()\n",
        "print(training_ratio)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.798506921794593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtY454BCk3iL",
        "outputId": "cb01a8b3-ebde-4897-f37e-968116e55883"
      },
      "source": [
        "flights_train.show(3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
            "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|            features|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
            "|  0|  1|  2|     AA|JFK|  6.58|     230|   50|2570.0|    1|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
            "|  0|  1|  2|     AA|JFK| 15.75|     185|   16|1519.0|    1|        1.0|    2.0|[0.0,1.0,2.0,1.0,...|\n",
            "|  0|  1|  2|     AA|LGA|  11.5|     195|  -11|1765.0|    0|        1.0|    3.0|[0.0,1.0,2.0,1.0,...|\n",
            "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBya68RltoWw"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Create a regression object and train on training data\n",
        "regression = LinearRegression(labelCol='delay').fit(flights_train)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e65fiIztnbs4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c930001-d3b1-4754-c31e-bbce12cc0c4e"
      },
      "source": [
        "# Create predictions for the testing data and take a look at the predictions\r\n",
        "predictions = regression.transform(flights_test)\r\n",
        "predictions.select('delay', 'prediction').show(5, False)\r\n",
        "\r\n",
        "# Calculate the RMSE\r\n",
        "RegressionEvaluator(labelCol='delay').evaluate(predictions)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------------------+\n",
            "|delay|prediction        |\n",
            "+-----+------------------+\n",
            "|31   |33.330984436174916|\n",
            "|52   |12.818073524277002|\n",
            "|109  |16.498319808799558|\n",
            "|21   |35.00913620284559 |\n",
            "|22   |39.750432756541635|\n",
            "+-----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.11496825480485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnHgqVnSz22k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}